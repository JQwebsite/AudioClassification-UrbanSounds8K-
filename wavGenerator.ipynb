{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    files.upload()\n",
    "    ! pip install -q kaggle\n",
    "    ! mkdir ~/.kaggle\n",
    "    ! cp kaggle.json ~/.kaggle/\n",
    "    ! chmod 600 ~/.kaggle/kaggle.json\n",
    "    ! kaggle datasets download -d chrisfilo/urbansound8k\n",
    "    ! unzip urbansound8k.zip -d UrbanSounds8K\n",
    "    !pip install ipytest\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import Augmentation\n",
    "\n",
    "augmentor = Augmentation.Augmentor(audio_channels=1, audio_duration=4000,audio_sampling=44100)\n",
    "\n",
    "ipytest.autoconfig()\n",
    "\n",
    "class_map = [\n",
    "    'air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling',\n",
    "    'engine idling', 'gunshot', 'jackhammer', 'siren', 'street music'\n",
    "]\n",
    "\n",
    "def load_audio_files(path, dataset):\n",
    "    walker = [str(p) for p in Path(path).glob(f'*.wav')]\n",
    "    for i, file_path in enumerate(walker,):\n",
    "        path, filename = os.path.split(file_path)\n",
    "        title, _ = os.path.splitext(filename)\n",
    "        fsID, classID, occurrenceID, sliceID = [\n",
    "            int(n) for n in title.split('-')\n",
    "        ]\n",
    "        # Load audio\n",
    "        waveform, sample_rate = pad_trunc(\n",
    "            augmentor.resample(augmentor.pad_trunc(torchaudio.load(file_path), 1), 44100), 4000)\n",
    "        assert waveform.shape == torch.Size(\n",
    "            [1, 176400]), f'Error: waveform shape is {waveform.shape}'\n",
    "        dataset.append([waveform[0], classID, title])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_spectrogram_images(trainloader, mode = \"train\"):\n",
    "    length = len(trainloader)\n",
    "    spectrogram = torchaudio.transforms.Spectrogram()\n",
    "    timeMask = torchaudio.transforms.TimeMasking(time_mask_param=80)\n",
    "    freqMask = torchaudio.transforms.FrequencyMasking(freq_mask_param=80)\n",
    "    num_TimeMask = 4\n",
    "    num_FreqMask = 4\n",
    "    num_FreqTimeMask = 4\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        waveform = data[0]\n",
    "        classID = data[1].item()\n",
    "        title = data[2][0]\n",
    "        directory = f'./UrbanSounds8K/spectrograms/{mode}/{class_map[classID]}/'\n",
    "        if(not os.path.isdir(directory)):\n",
    "            os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "\n",
    "        spectrogram_tensor = (spectrogram(waveform) + 1e-12).log2()\n",
    "\n",
    "        assert spectrogram_tensor.shape == torch.Size([1, 201, 883]), f\"Spectrogram size mismatch! {spectrogram_tensor.shape}\"\n",
    "\n",
    "        if mode ==\"train\":\n",
    "            # create transformed waveforms\n",
    "            for a in range(num_TimeMask):\n",
    "                masked_spectrogram_tensor = timeMask(spectrogram_tensor)\n",
    "                np.save(f'{directory}{title}-tm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "            for a in range(num_FreqMask):\n",
    "                masked_spectrogram_tensor = freqMask(spectrogram_tensor)\n",
    "                np.save(f'{directory}{title}-fm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "            for a in range(num_FreqTimeMask):\n",
    "                masked_spectrogram_tensor = freqMask(timeMask(spectrogram_tensor))\n",
    "                np.save(f'{directory}{title}-ftm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "        np.save(f'{directory}{title}-org_spec', spectrogram_tensor.flipud())\n",
    "        # break\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{mode}: {i}/{length}')\n",
    "\n",
    "    return (length)*(num_TimeMask + num_FreqMask + num_FreqTimeMask + 1) if mode==\"train\" else (length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_load():\n",
    "    walker = sorted(str(p) for p in Path(\"./test/\").glob(f'*.wav'))\n",
    "    for i, file_path in enumerate(walker):\n",
    "        assert torchaudio.load(file_path) \n",
    "\n",
    "def test_pad_trunc():\n",
    "    target_length = 4\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/1_44100_0830.wav'))[0][0]) == 44100*target_length\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/2_44100_2250.wav'))[0][0]) == 44100*target_length\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/2_44100_4000.wav'))[0][0]) == 44100*target_length\n",
    "\n",
    "def test_rechannel():\n",
    "    target_channel = 1\n",
    "    assert augmentor.rechannel(torchaudio.load('./test/1_44100_0830.wav'))[0].shape[0] == target_channel\n",
    "    assert augmentor.rechannel(torchaudio.load('./test/2_44100_4000.wav'))[0].shape[0] == target_channel\n",
    "\n",
    "def test_resample():\n",
    "    target_sr = 44100\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_11025_4000.wav'))[0][0]) == 4*target_sr\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_44100_0830.wav'))[0][0]) == 0.830*target_sr\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_96000_0310.wav'))[0][0]) == 0.310*target_sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 0\n"
     ]
    }
   ],
   "source": [
    "main_path = './UrbanSounds8K/'\n",
    "directory = [str(p) for p in Path(main_path).glob('fold*')][0:1]\n",
    "\n",
    "audio_dataset = []\n",
    "\n",
    "for path in directory:\n",
    "    print(\"Loading \", path)\n",
    "    audio_dataset = load_audio_files(path, audio_dataset)\n",
    "\n",
    "print(f\"Length of dataset: {len(audio_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(audio_dataset))\n",
    "\n",
    "val_size = len(audio_dataset) - train_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    audio_dataset, [train_size, val_size-50, 50])\n",
    "\n",
    "# Load training set\n",
    "audio_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_train = create_spectrogram_images(audio_dataloader, \"train\")\n",
    "\n",
    "# Load validating set\n",
    "audio_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_val = create_spectrogram_images(audio_dataloader, \"val\")\n",
    "\n",
    "# Load testing set\n",
    "audio_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_test = create_spectrogram_images(audio_dataloader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                                          [100%]\u001b[0m\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m________________________________ test_spectrogram_generation_train ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_spectrogram_generation_train\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m([\n",
      "            \u001b[96mstr\u001b[39;49;00m(p) \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m Path(\u001b[33m'\u001b[39;49;00m\u001b[33m./UrbanSounds8K/spectrograms/train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).glob(\u001b[33m'\u001b[39;49;00m\u001b[33m*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        ]) == \u001b[96mlen\u001b[39;49;00m(class_map)\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 0 == 10\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 0 = len([])\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  and   10 = len(['air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling', 'engine idling', ...])\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\JianQuan\\AppData\\Local\\Temp\\ipykernel_8096\\1425346925.py\u001b[0m:2: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________________ test_spectrogram_generation_val _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_spectrogram_generation_val\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m([\n",
      "            \u001b[96mstr\u001b[39;49;00m(p) \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m Path(\u001b[33m'\u001b[39;49;00m\u001b[33m./UrbanSounds8K/spectrograms/val\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).glob(\u001b[33m'\u001b[39;49;00m\u001b[33m*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        ]) == \u001b[96mlen\u001b[39;49;00m(class_map)\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 0 == 10\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 0 = len([])\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  and   10 = len(['air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling', 'engine idling', ...])\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\JianQuan\\AppData\\Local\\Temp\\ipykernel_8096\\1425346925.py\u001b[0m:14: AssertionError\n",
      "===================================== short test summary info =====================================\n",
      "FAILED tmpi5shdq1j.py::test_spectrogram_generation_train - AssertionError: assert 0 == 10\n",
      "FAILED tmpi5shdq1j.py::test_spectrogram_generation_val - AssertionError: assert 0 == 10\n",
      "\u001b[31m\u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.08s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_spectrogram_generation_train():\n",
    "    assert len([\n",
    "        str(p) for p in Path('./UrbanSounds8K/spectrograms/train').glob('*')\n",
    "    ]) == len(class_map)\n",
    "\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/train').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "    assert sum == num_train\n",
    "\n",
    "def test_spectrogram_generation_val():\n",
    "    assert len([\n",
    "        str(p) for p in Path('./UrbanSounds8K/spectrograms/val').glob('*')\n",
    "    ]) == len(class_map)\n",
    "\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/val').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "\n",
    "    assert sum == num_val\n",
    "\n",
    "def test_spectrogram_generation_test():\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/test').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "\n",
    "    assert sum == num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './UrbanSounds8K/spectrograms/train/gunshot/102305-6-0-0-fm0_spec.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# maybe autoload the first file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_load \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./UrbanSounds8K/spectrograms/train/gunshot/102305-6-0-0-fm0_spec.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(test_load[\u001b[38;5;241m0\u001b[39m], origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './UrbanSounds8K/spectrograms/train/gunshot/102305-6-0-0-fm0_spec.npy'"
     ]
    }
   ],
   "source": [
    "# maybe autoload the first file\n",
    "\n",
    "test_load = np.load(\n",
    "    './UrbanSounds8K/spectrograms/train/gunshot/102305-6-0-0-fm0_spec.npy')\n",
    "plt.imshow(test_load[0], origin=\"lower\")\n",
    "plt.colorbar()\n",
    "print(test_load.min(), \" \", test_load.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"./UrbanSounds8K/fold1/102305-6-0-0.wav\"\n",
    "# waveform, sample_rate = rechannel(torchaudio.load(filename), 1)\n",
    "# fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(waveform.t().numpy())\n",
    "# show_spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform, sr = pad_trunc(rechannel(torchaudio.load(filename), 1), 4000)\n",
    "# fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(waveform.t().numpy())\n",
    "# show_spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dataset = []\n",
    "# sum = 0\n",
    "\n",
    "# main_path = './UrbanSounds8K/spectrograms/'\n",
    "\n",
    "# dir = [str(p) for p in Path(main_path).glob('*')]\n",
    "# for path in dir:\n",
    "#   print('Loading: '+ path)\n",
    "#   num = len([str(p) for p in Path(path).glob('*')])\n",
    "#   sum += num\n",
    "#   print(num)\n",
    "\n",
    "# sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e87201990ab3ef9f8e8015a432b605669f23d2887f787d8acc74a222f9112d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

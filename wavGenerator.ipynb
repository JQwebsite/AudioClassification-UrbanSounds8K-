{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    files.upload()\n",
    "    ! pip install -q kaggle\n",
    "    ! mkdir ~/.kaggle\n",
    "    ! cp kaggle.json ~/.kaggle/\n",
    "    ! chmod 600 ~/.kaggle/kaggle.json\n",
    "    ! kaggle datasets download -d chrisfilo/urbansound8k\n",
    "    ! unzip urbansound8k.zip -d UrbanSounds8K\n",
    "    !pip install ipytest\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import Augmentation\n",
    "\n",
    "augmentor = Augmentation.Augmentor()\n",
    "\n",
    "ipytest.autoconfig()\n",
    "\n",
    "class_map = [\n",
    "    'air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling',\n",
    "    'engine idling', 'gunshot', 'jackhammer', 'siren', 'street music'\n",
    "]\n",
    "\n",
    "def load_audio_files(path, dataset):\n",
    "    walker = [str(p) for p in Path(path).glob(f'*.wav')]\n",
    "    for i, file_path in enumerate(walker,):\n",
    "        path, filename = os.path.split(file_path)\n",
    "        title, _ = os.path.splitext(filename)\n",
    "        fsID, classID, occurrenceID, sliceID = [\n",
    "            int(n) for n in title.split('-')\n",
    "        ]\n",
    "        # Load audio\n",
    "        waveform, sample_rate = augmentor.pad_trunc(\n",
    "            augmentor.resample(augmentor.rechannel(\n",
    "                torchaudio.load(file_path))))\n",
    "        assert waveform.shape == torch.Size(\n",
    "            [1, 176400]), f'Error: waveform shape is {waveform.shape}'\n",
    "        dataset.append([waveform[0], classID, title])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_spectrogram_images(trainloader, mode = \"train\"):\n",
    "    length = len(trainloader)\n",
    "    spectrogram = torchaudio.transforms.Spectrogram()\n",
    "    timeMask = torchaudio.transforms.TimeMasking(time_mask_param=80)\n",
    "    freqMask = torchaudio.transforms.FrequencyMasking(freq_mask_param=80)\n",
    "    num_TimeMask = 4\n",
    "    num_FreqMask = 4\n",
    "    num_FreqTimeMask = 4\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        waveform = data[0]\n",
    "        classID = data[1].item()\n",
    "        title = data[2][0]\n",
    "        directory = f'./UrbanSounds8K/spectrograms/{mode}/{class_map[classID]}/'\n",
    "        if(not os.path.isdir(directory)):\n",
    "            os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "\n",
    "        spectrogram_tensor = (spectrogram(waveform) + 1e-12).log2()\n",
    "\n",
    "        assert spectrogram_tensor.shape == torch.Size([1, 201, 883]), f\"Spectrogram size mismatch! {spectrogram_tensor.shape}\"\n",
    "\n",
    "        if mode == \"train\":\n",
    "            # create transformed waveforms\n",
    "            for a in range(num_TimeMask):\n",
    "                masked_spectrogram_tensor = timeMask(spectrogram_tensor)\n",
    "                np.save(f'{directory}{title}-tm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "            for a in range(num_FreqMask):\n",
    "                masked_spectrogram_tensor = freqMask(spectrogram_tensor)\n",
    "                np.save(f'{directory}{title}-fm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "            for a in range(num_FreqTimeMask):\n",
    "                masked_spectrogram_tensor = freqMask(timeMask(spectrogram_tensor))\n",
    "                np.save(f'{directory}{title}-ftm{a}_spec',\n",
    "                        masked_spectrogram_tensor.flipud())\n",
    "\n",
    "        np.save(f'{directory}{title}-org_spec', spectrogram_tensor.flipud())\n",
    "        # break\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{mode}: {i}/{length}')\n",
    "\n",
    "    return (length)*(num_TimeMask + num_FreqMask + num_FreqTimeMask + 1) if mode==\"train\" else (length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_load():\n",
    "    walker = sorted(str(p) for p in Path(\"./test/\").glob(f'*.wav'))\n",
    "    for i, file_path in enumerate(walker):\n",
    "        assert torchaudio.load(file_path) \n",
    "\n",
    "def test_pad_trunc():\n",
    "    target_length = 4\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/1_44100_0830.wav'))[0][0]) == 44100*target_length\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/2_44100_2250.wav'))[0][0]) == 44100*target_length\n",
    "    assert len(augmentor.pad_trunc(torchaudio.load('./test/2_44100_4000.wav'))[0][0]) == 44100*target_length\n",
    "\n",
    "def test_rechannel():\n",
    "    target_channel = 1\n",
    "    assert augmentor.rechannel(torchaudio.load('./test/1_44100_0830.wav'))[0].shape[0] == target_channel\n",
    "    assert augmentor.rechannel(torchaudio.load('./test/2_44100_4000.wav'))[0].shape[0] == target_channel\n",
    "\n",
    "def test_resample():\n",
    "    target_sr = 44100\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_11025_4000.wav'))[0][0]) == 4*target_sr\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_44100_0830.wav'))[0][0]) == 0.830*target_sr\n",
    "    assert len(augmentor.resample(torchaudio.load('./test/1_96000_0310.wav'))[0][0]) == 0.310*target_sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = './UrbanSounds8K/'\n",
    "directory = [str(p) for p in Path(main_path).glob('fold*')]\n",
    "\n",
    "audio_dataset = []\n",
    "\n",
    "for path in directory[0:8]:\n",
    "    print(\"Loading \", path)\n",
    "    audio_dataset = load_audio_files(path, audio_dataset)\n",
    "\n",
    "test_dataset=[]\n",
    "test_dataset = load_audio_files(directory[9], test_dataset)\n",
    "\n",
    "print(f\"Length of dataset: {len(audio_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(audio_dataset))\n",
    "\n",
    "val_size = len(audio_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    audio_dataset, [train_size, val_size])\n",
    "\n",
    "# Load training set\n",
    "audio_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_train = create_spectrogram_images(audio_dataloader, \"train\")\n",
    "\n",
    "# Load validating set\n",
    "audio_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_val = create_spectrogram_images(audio_dataloader, \"val\")\n",
    "\n",
    "\n",
    "# Load testing set\n",
    "audio_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "num_test = create_spectrogram_images(audio_dataloader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_spectrogram_generation_train():\n",
    "    assert len([\n",
    "        str(p) for p in Path('./UrbanSounds8K/spectrograms/train').glob('*')\n",
    "    ]) == len(class_map)\n",
    "\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/train').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "    assert sum == num_train\n",
    "\n",
    "def test_spectrogram_generation_val():\n",
    "    assert len([\n",
    "        str(p) for p in Path('./UrbanSounds8K/spectrograms/val').glob('*')\n",
    "    ]) == len(class_map)\n",
    "\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/val').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "\n",
    "    assert sum == num_val\n",
    "\n",
    "def test_spectrogram_generation_test():\n",
    "    sum = 0\n",
    "    dir = [str(p) for p in Path('./UrbanSounds8K/spectrograms/test').glob('*')]\n",
    "    for path in dir:\n",
    "        num = len([str(p) for p in Path(path).glob('*')])\n",
    "        sum += num\n",
    "\n",
    "    assert sum == num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe autoload the first file\n",
    "\n",
    "test_load = np.load(\n",
    "    './UrbanSounds8K/spectrograms/train/gunshot/102305-6-0-0-fm0_spec.npy')\n",
    "plt.imshow(test_load[0], origin=\"lower\")\n",
    "plt.colorbar()\n",
    "print(test_load.min(), \" \", test_load.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"./UrbanSounds8K/fold1/102305-6-0-0.wav\"\n",
    "# waveform, sample_rate = rechannel(torchaudio.load(filename), 1)\n",
    "# fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(waveform.t().numpy())\n",
    "# show_spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform, sr = pad_trunc(rechannel(torchaudio.load(filename), 1), 4000)\n",
    "# fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(waveform.t().numpy())\n",
    "# show_spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dataset = []\n",
    "# sum = 0\n",
    "\n",
    "# main_path = './UrbanSounds8K/spectrograms/'\n",
    "\n",
    "# dir = [str(p) for p in Path(main_path).glob('*')]\n",
    "# for path in dir:\n",
    "#   print('Loading: '+ path)\n",
    "#   num = len([str(p) for p in Path(path).glob('*')])\n",
    "#   sum += num\n",
    "#   print(num)\n",
    "\n",
    "# sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e87201990ab3ef9f8e8015a432b605669f23d2887f787d8acc74a222f9112d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "OksgqWXLlGzx"
            },
            "source": [
                "**Actual Machine Learning**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'mlmodel'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlmodel\u001b[39;00m\n\u001b[0;32m     14\u001b[0m audio_paths \u001b[38;5;241m=\u001b[39m Augmentation\u001b[38;5;241m.\u001b[39mgetAudioPaths(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m audio_train_paths, audio_val_paths \u001b[38;5;241m=\u001b[39m audio_paths[:\u001b[38;5;28mint\u001b[39m(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(audio_paths))], audio_paths[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(audio_paths)):]\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlmodel'"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import Augmentation\n",
                "import torchaudio\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torchvision import datasets\n",
                "import numpy as np\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from datetime import datetime\n",
                "import os\n",
                "import mlmodel\n",
                "\n",
                "audio_paths = Augmentation.getAudioPaths('./data/')\n",
                "\n",
                "audio_train_paths, audio_val_paths = audio_paths[:int(\n",
                "    0.8 * len(audio_paths))], audio_paths[int(0.8 * len(audio_paths)):]\n",
                "\n",
                "\n",
                "audio_train_dataset = Augmentation.AudioDataset(\n",
                "    audio_train_paths,\n",
                "    transformList=[\n",
                "        torchaudio.transforms.TimeMasking(time_mask_param=80),\n",
                "        torchaudio.transforms.FrequencyMasking(freq_mask_param=80),\n",
                "    ])\n",
                "\n",
                "audio_val_dataset = Augmentation.AudioDataset(audio_val_paths)\n",
                "\n",
                "train_dataloader = torch.utils.data.DataLoader(audio_train_dataset,\n",
                "                                               batch_size=4,\n",
                "                                               num_workers=0,\n",
                "                                               shuffle=True)\n",
                "\n",
                "val_dataloader = torch.utils.data.DataLoader(audio_val_dataset,\n",
                "                                              batch_size=4,\n",
                "                                              num_workers=0,\n",
                "                                              shuffle=True,\n",
                "                                             )\n",
                "\n",
                "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18')\n",
                "\n",
                "model.conv1 = nn.Conv2d(1,\n",
                "                        64,\n",
                "                        kernel_size=(7, 7),\n",
                "                        stride=(2, 2),\n",
                "                        padding=(3, 3),\n",
                "                        bias=False)\n",
                "\n",
                "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
                "\n",
                "\n",
                "title = datetime.now().strftime(\"%Y-%m-%d,%H-%M-%S\")\n",
                "title = False\n",
                "\n",
                "mymodel = mlmodel.mlmodel(model, train_dataloader, val_dataloader, title)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# mymodel.write_tb_graph(train_dataloader)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 432
                },
                "id": "obI3fgwAQhLP",
                "outputId": "8df092c6-e4c0-46f0-fcc8-fb2e7903291a"
            },
            "outputs": [],
            "source": [
                "cost = torch.nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "def interateModel(epochs):\n",
                "    for epoch in range(epochs):\n",
                "        print(f'Epoch {epoch+1}/{epochs}\\n-------------------------------')\n",
                "        train_loss, train_accuracy = mymodel.train(cost, optimizer)\n",
                "        val_loss, val_accuracy = mymodel.val(cost)\n",
                "        tune.report(mean_accuracy=val_accuracy)\n",
                "        print(f'Training | Loss: {train_loss} Accuracy: {train_accuracy}%')\n",
                "        print(f'Validating  | Loss: {val_loss} Accuracy: {val_accuracy}% \\n')\n",
                "        mymodel.tensorBoardLogging(train_loss, train_accuracy, val_loss,\n",
                "                                   val_accuracy, epoch)\n",
                "        print('Done!')\n",
                "\n",
                "\n",
                "interateModel(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model.load_state_dict(\n",
                "#     torch.load(\"./model/model_t4,f4,tf4.pt\", map_location=device))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.save(mymodel.getModel().state_dict(), f\"./model/model_t4,f4,tf4.pt\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.10.6 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "vscode": {
            "interpreter": {
                "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "int(config['augmentations']['sample_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import machineLearning\n",
    "from AudioDataset import AudioDataset\n",
    "import Augmentation\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_paths = [str(p) for p in Path('./saved_model/').glob(f'*.pt')]\n",
    "for i, model_path in enumerate(model_paths):\n",
    "    print(f'[{i}] {model_path}')\n",
    "\n",
    "path = model_paths[int(input('Select saved model > '))]\n",
    "model = torch.load(path, map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.io import StreamReader\n",
    "from Augmentation import Augmentor\n",
    "\n",
    "augmentor = Augmentor()\n",
    "\n",
    "streamer = StreamReader(\n",
    "    src=\"audio=@device_cm_{33D9A762-90C8-11D0-BD43-00A0C911CE86}\\wave_{07DEF3C3-A487-4CE6-A6E3-535301DF2D46}\",\n",
    "    format=\"dshow\",\n",
    ")\n",
    "\n",
    "streamer.add_basic_audio_stream(\n",
    "    frames_per_chunk=44100*4, sample_rate=44100)\n",
    "\n",
    "class_map = ['air conditioner', 'car horn', 'children playing', 'dog bark',\n",
    "             'drilling', 'engine idling', 'gunshot', 'jackhammer', 'siren', 'street music']\n",
    "             \n",
    "print(streamer.get_src_stream_info(0))\n",
    "print(streamer.get_out_stream_info(0))\n",
    "stream_iterator = streamer.stream()\n",
    "wav = torch.Tensor([])\n",
    "sm = torch.nn.Softmax()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "        (chunk,) = next(stream_iterator)\n",
    "        # wav = torch.cat((wav, chunk[:, 0]))\n",
    "        spectrogram = torchaudio.transforms.Spectrogram()\n",
    "        wav, sr = augmentor.audio_preprocessing([chunk.T, 44100])\n",
    "        \n",
    "        spectrogram_tensor = (spectrogram(wav) + 1e-12).log2()\n",
    "        pred = model(torch.unsqueeze(spectrogram_tensor, 0))\n",
    "        pred = sm(pred)\n",
    "        print(class_map[pred.argmax()])\n",
    "        sn.barplot(y=class_map, x=pred[0].cpu().numpy())\n",
    "        plt.show()\n",
    "\n",
    "streamer.remove_stream(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "\n",
    "print(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import testModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_paths = [str(p) for p in Path('./saved_model/').glob(f'*.pt')]\n",
    "for i, model_path in enumerate(model_paths):\n",
    "    print(f'[{i}] {model_path}')\n",
    "\n",
    "path = model_paths[int(input('Select saved model > '))]\n",
    "model = torch.load(path, map_location=device)\n",
    "testModel.predictFile('./test/test.wav', model, device)\n",
    "testModel.predictFolder('./data/testset/', model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aae5a0cc235b73d0e2ae2fec9587033b694f5ff905454d3372caf9462ad28deb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

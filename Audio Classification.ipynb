{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "OksgqWXLlGzx"
            },
            "source": [
                "**Actual Machine Learning**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "-XHxisXgPOeN"
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from torchvision import datasets\n",
                "import numpy as np\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from datetime import datetime\n",
                "import os\n",
                "import time\n",
                "from torch.utils.tensorboard import SummaryWriter\n",
                "\n",
                "def npy_loader(path):\n",
                "    return torch.from_numpy(np.load(path))\n",
                "\n",
                "def train(dataloader, model, optimizer):\n",
                "    train_size = len(dataloader.dataset)\n",
                "    batch_size = len(next(iter(dataloader))[1])\n",
                "    total_batch = len(dataloader)\n",
                "    train_loss, train_accuracy = 0, 0\n",
                "\n",
                "    model.train()\n",
                "\n",
                "    for batch, (X, Y) in enumerate(dataloader):\n",
                "        X, Y = X.to(device), Y.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        pred = model(X)\n",
                "        batch_loss = cost(pred, Y)\n",
                "        batch_loss.backward()\n",
                "        optimizer.step()\n",
                "        batch_accuracy = (pred.argmax(1)==Y).type(torch.float).sum()\n",
                "        train_loss += batch_loss.item()\n",
                "        train_accuracy += batch_accuracy.item()\n",
                "        if batch % 100 == 0:\n",
                "            print(\n",
                "                f\"Training batch {batch}/{total_batch} -> Loss: {batch_loss.item()}  Accuracy: {batch_accuracy.item()/batch_size*100}%\"\n",
                "            )\n",
                "    train_loss /= train_size\n",
                "    train_accuracy /= train_size/100\n",
                "    return(train_loss, train_accuracy)\n",
                "\n",
                "def val(dataloader, model):\n",
                "    val_size = len(dataloader.dataset)\n",
                "    total_batch = len(dataloader)\n",
                "    val_loss, val_accuracy = 0, 0\n",
                "\n",
                "    model.eval()\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for batch, (X, Y) in enumerate(dataloader):\n",
                "            X, Y = X.to(device), Y.to(device)\n",
                "            pred = model(X)\n",
                "            batch_loss = cost(pred, Y)\n",
                "            batch_accuracy = (pred.argmax(1)==Y).type(torch.float).sum()\n",
                "            val_loss += batch_loss.item()\n",
                "            val_accuracy += batch_accuracy.item()\n",
                "        if batch % 10 == 0:\n",
                "            print(\n",
                "                f\"Validation batch {batch}/{total_batch} -> Loss: {batch_loss.item()}  Accuracy: {batch_accuracy.item()/batch_size*100}%\"\n",
                "            )\n",
                "\n",
                "    val_loss /= val_size\n",
                "    val_accuracy /= val_size/100\n",
                "    return(val_loss, val_accuracy)\n",
                "\n",
                "def tensorBoardLogging(train_loss, train_accuracy, val_loss, val_accuracy,\n",
                "                       epoch):\n",
                "    writer.add_scalar('1 Training/1 Model loss', train_loss, epoch)\n",
                "    writer.add_scalar('1 Training/2 Model accuracy', train_accuracy, epoch)\n",
                "    writer.add_scalar('2 Validate/1 Model loss', val_loss, epoch)\n",
                "    writer.add_scalar('2 Validate/2 Model accuracy', val_accuracy, epoch)\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "VHCkJ1iPqSiu",
                "outputId": "e4d42133-d1b6-4ae9-82ab-71efab8aa770"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training size: 9074\n",
                        "Validation size: 175\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in C:\\Users\\jianq/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "device(type='cpu')"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "audio_train_dataset = datasets.DatasetFolder(root='./UrbanSounds8K/spectrograms/train/',\n",
                "                                       loader=npy_loader,\n",
                "                                       extensions=['.npy'])\n",
                "\n",
                "audio_val_dataset = datasets.DatasetFolder(root='./UrbanSounds8K/spectrograms/val/',\n",
                "                                       loader=npy_loader,\n",
                "                                       extensions=['.npy'])\n",
                "\n",
                "print(\"Training size:\", len(audio_train_dataset))\n",
                "print(\"Validation size:\",len(audio_val_dataset))\n",
                "\n",
                "train_dataloader = torch.utils.data.DataLoader(audio_train_dataset,\n",
                "                                               batch_size=12,\n",
                "                                               num_workers=0,\n",
                "                                               shuffle=True)\n",
                "\n",
                "val_dataloader = torch.utils.data.DataLoader(audio_val_dataset,\n",
                "                                              batch_size=12,\n",
                "                                              num_workers=0,\n",
                "                                              shuffle=True,\n",
                "                                             )\n",
                "\n",
                "\n",
                "\n",
                "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18')\n",
                "model.conv1 = nn.Conv2d(1,\n",
                "                        64,\n",
                "                        kernel_size=(7, 7),\n",
                "                        stride=(2, 2),\n",
                "                        padding=(3, 3),\n",
                "                        bias=False)\n",
                "                        \n",
                "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
                "\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = model.to(device)\n",
                "\n",
                "# Check that it is on Cuda\n",
                "next(model.parameters()).device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "-MJQlAMOlfMn"
            },
            "outputs": [],
            "source": [
                "# rm -rf ./logsdir/ # remove all logs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "4aFppr-urj8t"
            },
            "source": [
                "Tensorboard model graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "bQEUozxSkwc9"
            },
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m spec, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_dataloader))\n\u001b[0;32m      4\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\tensorboard\\writer.py:840\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    836\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_once(\u001b[39m\"\u001b[39m\u001b[39mtensorboard.logging.add_graph\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    838\u001b[0m     \u001b[39m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m    839\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_graph(\n\u001b[1;32m--> 840\u001b[0m         graph(model, input_to_model, verbose, use_strict_trace)\n\u001b[0;32m    841\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    843\u001b[0m     \u001b[39m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:338\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mselect_model_mode_for_export(\n\u001b[0;32m    335\u001b[0m     model, torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mTrainingMode\u001b[39m.\u001b[39mEVAL\n\u001b[0;32m    336\u001b[0m ):  \u001b[39m# TODO: move outside of torch.onnx?\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m         trace \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, args, strict\u001b[39m=\u001b[39;49muse_strict_trace)\n\u001b[0;32m    339\u001b[0m         graph \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mgraph\n\u001b[0;32m    340\u001b[0m         torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_inline(graph)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[0;32m    749\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m--> 750\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    751\u001b[0m         func,\n\u001b[0;32m    752\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[0;32m    753\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    754\u001b[0m         check_trace,\n\u001b[0;32m    755\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[0;32m    756\u001b[0m         check_tolerance,\n\u001b[0;32m    757\u001b[0m         strict,\n\u001b[0;32m    758\u001b[0m         _force_outplace,\n\u001b[0;32m    759\u001b[0m         _module_class,\n\u001b[0;32m    760\u001b[0m     )\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    763\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    764\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[0;32m    765\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m ):\n\u001b[0;32m    767\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    768\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[0;32m    769\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m         _module_class,\n\u001b[0;32m    777\u001b[0m     )\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:992\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    981\u001b[0m                 _check_trace(\n\u001b[0;32m    982\u001b[0m                     check_inputs,\n\u001b[0;32m    983\u001b[0m                     func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    989\u001b[0m                     _module_class,\n\u001b[0;32m    990\u001b[0m                 )\n\u001b[0;32m    991\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 992\u001b[0m                 _check_trace(\n\u001b[0;32m    993\u001b[0m                     [inputs],\n\u001b[0;32m    994\u001b[0m                     func,\n\u001b[0;32m    995\u001b[0m                     check_trace_method,\n\u001b[0;32m    996\u001b[0m                     check_tolerance,\n\u001b[0;32m    997\u001b[0m                     strict,\n\u001b[0;32m    998\u001b[0m                     _force_outplace,\n\u001b[0;32m    999\u001b[0m                     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1000\u001b[0m                     _module_class,\n\u001b[0;32m   1001\u001b[0m                 )\n\u001b[0;32m   1002\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1003\u001b[0m     torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_trace\u001b[39m.\u001b[39m_trace_module_map \u001b[39m=\u001b[39m old_module_map\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:330\u001b[0m, in \u001b[0;36m_check_trace\u001b[1;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mfor\u001b[39;00m name, data \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    329\u001b[0m     copied_dict[name] \u001b[39m=\u001b[39m _clone_inputs(data)\n\u001b[1;32m--> 330\u001b[0m check_mod \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace_module(\n\u001b[0;32m    331\u001b[0m     func\u001b[39m.\u001b[39;49m\u001b[39m__self__\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mhasattr\u001b[39;49m(func, \u001b[39m\"\u001b[39;49m\u001b[39m__self__\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39melse\u001b[39;49;00m func,\n\u001b[0;32m    332\u001b[0m     copied_dict,\n\u001b[0;32m    333\u001b[0m     check_trace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    334\u001b[0m     strict\u001b[39m=\u001b[39;49mstrict,\n\u001b[0;32m    335\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49mforce_outplace,\n\u001b[0;32m    336\u001b[0m     _module_class\u001b[39m=\u001b[39;49m_module_class,\n\u001b[0;32m    337\u001b[0m     _compilation_unit\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mCompilationUnit(),\n\u001b[0;32m    338\u001b[0m )\n\u001b[0;32m    339\u001b[0m check_mod_func \u001b[39m=\u001b[39m check_mod\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(traced_func\u001b[39m.\u001b[39mname)\n\u001b[0;32m    340\u001b[0m inputs \u001b[39m=\u001b[39m inputs[traced_func\u001b[39m.\u001b[39mname]\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\jit\\_trace.py:967\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    963\u001b[0m     argument_names \u001b[39m=\u001b[39m get_callable_argument_names(func)\n\u001b[0;32m    965\u001b[0m example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m--> 967\u001b[0m module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[0;32m    968\u001b[0m     method_name,\n\u001b[0;32m    969\u001b[0m     func,\n\u001b[0;32m    970\u001b[0m     example_inputs,\n\u001b[0;32m    971\u001b[0m     var_lookup_fn,\n\u001b[0;32m    972\u001b[0m     strict,\n\u001b[0;32m    973\u001b[0m     _force_outplace,\n\u001b[0;32m    974\u001b[0m     argument_names,\n\u001b[0;32m    975\u001b[0m )\n\u001b[0;32m    976\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[0;32m    978\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[0;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "title = datetime.now().strftime(\"%Y-%m-%d,%H-%M-%S\")\n",
                "title=\"freqTimeFulldataset10out2\"\n",
                "spec, label = next(iter(train_dataloader))\n",
                "writer = SummaryWriter(f'./logs/{title}')\n",
                "writer.add_graph(model, spec.to(device))\n",
                "writer.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "id": "aVrAKQinQfWA"
            },
            "outputs": [],
            "source": [
                "cost = torch.nn.CrossEntropyLoss()\n",
                "learning_rate = 0.001\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.load_state_dict(\n",
                "    torch.load(\"./model/model_t4,f4,tf4_10.pt\", map_location=device))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 432
                },
                "id": "obI3fgwAQhLP",
                "outputId": "8df092c6-e4c0-46f0-fcc8-fb2e7903291a"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n",
                        "-------------------------------\n",
                        "Training batch 0/757 -> Loss: 2.3602702617645264  Accuracy: 50.0%\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 5\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m val(val_dataloader, model)\n\u001b[0;32m      7\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
                        "Cell \u001b[1;32mIn [1], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer)\u001b[0m\n\u001b[0;32m     26\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m cost(pred, Y)\n\u001b[0;32m     27\u001b[0m batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 28\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m batch_accuracy \u001b[38;5;241m=\u001b[39m (pred\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m==\u001b[39mY)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     30\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    158\u001b[0m          grads,\n\u001b[0;32m    159\u001b[0m          exp_avgs,\n\u001b[0;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    162\u001b[0m          state_steps,\n\u001b[0;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m func(params,\n\u001b[0;32m    214\u001b[0m      grads,\n\u001b[0;32m    215\u001b[0m      exp_avgs,\n\u001b[0;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    218\u001b[0m      state_steps,\n\u001b[0;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
                        "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    303\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[0;32m    307\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "epochs = 20\n",
                "for epoch in range(epochs):\n",
                "    print(f'Epoch {epoch+1}/{epochs}\\n-------------------------------')\n",
                "    start = time.time()\n",
                "    train_loss, train_accuracy = train(train_dataloader, model, optimizer)\n",
                "    val_loss, val_accuracy = val(val_dataloader, model)\n",
                "    end = time.time()\n",
                "    print(f\"\\nEpoch duration: {end - start} seconds\")\n",
                "    print(f'Training | Loss: {train_loss} Accuracy: {train_accuracy}%')\n",
                "    print(f'Validating  | Loss: {val_loss} Accuracy: {val_accuracy}% \\n')\n",
                "    tensorBoardLogging(train_loss, train_accuracy, val_loss, val_accuracy, epoch)\n",
                "\n",
                "print('Done!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_loss, val_accuracy = val(val_dataloader, model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.save(model.state_dict(), f\"./model/model_t4,f4,tf4.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "DIAP8Nvg88ag"
            },
            "source": [
                "**Debugging**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "RumP79RPD4v6",
                "outputId": "158f193d-1fbe-4000-90b8-97bb285389bc"
            },
            "outputs": [],
            "source": [
                "\n",
                "# audio_dataset = []\n",
                "# sum = 0\n",
                "\n",
                "# main_path = './UrbanSounds8K/spectrograms/'\n",
                "\n",
                "# dir = [str(p) for p in Path(main_path).glob('*')]\n",
                "# for path in dir:\n",
                "#   print('Loading: '+ path)\n",
                "#   num = len([str(p) for p in Path(path).glob('*')])\n",
                "#   sum += num\n",
                "#   print(num)\n",
                "\n",
                "# sum"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.10.7 64-bit (microsoft store)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.7"
        },
        "vscode": {
            "interpreter": {
                "hash": "5e0ea5c72d63ec74a3e65528804f354af75f9a6d7105333063f2a8079cd404aa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
